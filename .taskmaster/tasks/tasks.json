{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Update Google Sheet with Pick # Formula Column",
        "description": "Add a formula column to the Google Sheet that auto-calculates pick numbers as =ROW()-1, eliminating the need for code-based pick number computation and preventing race conditions",
        "details": "Manual task in Google Sheets:\n1. Open the target Google Sheet (1h1uDCZPqJovFfUKPzfPgUwUOHjFdCXHWVhUE6VvFA_s)\n2. Insert a new column or modify the existing 'Pick' column\n3. Set the formula in the Pick column (starting from row 2, assuming row 1 is header): =ROW()-1\n4. Apply formula to all existing rows and set it to auto-fill for new rows\n5. Verify that all 300+ existing rows have correct pick numbers\n6. Document this change in the sheet structure\n\nThis is a prerequisite for the pipeline code changes, as the code will no longer compute pick numbers but will read them from this formula column after appending rows.",
        "testStrategy": "Manual verification: Check that pick numbers match row numbers minus 1. Add a test row via the existing GUI and confirm the formula auto-populates correctly.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T03:11:54.124Z"
      },
      {
        "id": "2",
        "title": "Create URL Validation Module",
        "description": "Implement a validation module to verify Spotify album URLs using regex pattern matching and extract album IDs",
        "details": "Create src/validation.py with:\n\ndef is_valid_spotify_album_url(url: str) -> bool:\n    \"\"\"Check if URL matches Spotify album pattern.\n    Valid formats:\n    - https://open.spotify.com/album/{album_id}\n    - https://open.spotify.com/album/{album_id}?si=...\n    \"\"\"\n    pattern = r'^https://open\\.spotify\\.com/album/[a-zA-Z0-9]{22}(\\?.*)?$'\n    return bool(re.match(pattern, url))\n\ndef extract_spotify_album_id(url: str) -> Optional[str]:\n    \"\"\"Extract album ID from Spotify URL.\n    Returns 22-character album ID or None if invalid.\n    \"\"\"\n    match = re.search(r'/album/([a-zA-Z0-9]{22})', url)\n    return match.group(1) if match else None\n\ndef validate_album_metadata(album_info: dict) -> tuple[bool, str]:\n    \"\"\"Validate that all required fields are present in Spotify response.\n    Returns (is_valid, error_message)\n    \"\"\"\n    required_fields = ['Artist', 'Album', 'Year', 'spotify_album_url', 'artwork_url']\n    missing = [f for f in required_fields if not album_info.get(f)]\n    if missing:\n        return False, f\"Missing required fields: {', '.join(missing)}\"\n    return True, \"\"\n\nUpdate environment.yml to include python-telegram-bot if not present.",
        "testStrategy": "Unit tests in tests/test_validation.py:\n- Test valid album URLs (with and without query params)\n- Test invalid URLs (tracks, playlists, artists, malformed)\n- Test album ID extraction\n- Test metadata validation with complete and incomplete data\n- Mock Spotify responses for edge cases",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T03:26:14.375Z"
      },
      {
        "id": "3",
        "title": "Implement Deduplication Logic",
        "description": "Add functionality to check if an album already exists in the Google Sheet based on Spotify album ID before adding",
        "details": "Extend src/add_album.py with:\n\ndef get_existing_album_ids(worksheet) -> dict[str, tuple[int, str]]:\n    \"\"\"Return dict mapping album_id -> (pick_number, date).\n    Read the 'spotify_album_url' column and extract IDs.\n    \"\"\"\n    header_row, header_map = get_header_row_and_map(worksheet)\n    url_col_idx = header_map.get('spotify_album_url')\n    if url_col_idx is None:\n        return {}\n    \n    url_values = worksheet.col_values(url_col_idx + 1)  # gspread is 1-indexed\n    pick_values = worksheet.col_values(header_map.get('pick', 0) + 1)\n    date_values = worksheet.col_values(header_map.get('date', 1) + 1)\n    \n    existing = {}\n    for i, url in enumerate(url_values[header_row:], start=header_row):\n        if url:\n            album_id = extract_spotify_album_id(url)\n            if album_id:\n                pick = pick_values[i] if i < len(pick_values) else ''\n                date = date_values[i] if i < len(date_values) else ''\n                existing[album_id] = (pick, date)\n    return existing\n\ndef check_duplicate(url: str, worksheet) -> tuple[bool, Optional[str]]:\n    \"\"\"Check if album already exists.\n    Returns (is_duplicate, message).\n    \"\"\"\n    album_id = extract_spotify_album_id(url)\n    if not album_id:\n        return False, None\n    \n    existing = get_existing_album_ids(worksheet)\n    if album_id in existing:\n        pick, date = existing[album_id]\n        return True, f\"Already added â€” Pick #{pick} on {date}\"\n    return False, None\n\nIntegrate into add_album() before calling get_album_info().",
        "testStrategy": "Unit tests:\n- Test dedup detection with existing album ID in sheet\n- Test no-duplicate scenario with new album\n- Test with empty sheet\n- Mock worksheet.col_values() to return test data\n- Verify correct pick/date returned in duplicate message",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T03:34:23.415Z"
      },
      {
        "id": "4",
        "title": "Update add_album.py to Extract and Store Album ID",
        "description": "Modify get_album_info() to extract and return spotify_album_id from the Spotify API response",
        "details": "Update get_album_info() in src/add_album.py:\n\ndef get_album_info(url='', spot_api=None):\n    try:\n        raw_info = spot_api.album(url)\n    except SpotifyException as e:\n        if e.http_status == 400:\n            print('exception')\n            return None\n    \n    # Extract album ID from response (not from URL)\n    album_id = raw_info.get('id', '')\n    \n    artist = raw_info['artists'][0]['name']\n    album = raw_info['name']\n    release_date = raw_info['release_date']\n    release_date_precision = raw_info['release_date_precision']\n    \n    if release_date_precision == 'day':\n        year = datetime.strptime(release_date, '%Y-%m-%d').year\n    else:\n        year = release_date\n    artwork_url = raw_info['images'][1]['url']\n    \n    to_return = {\n        \"spotify_album_id\": album_id,  # NEW\n        \"Artist\": artist,\n        \"Album\": album,\n        \"Year\": year,\n        \"spotify_album_url\": url,\n        \"artwork_url\": artwork_url\n    }\n    \n    return to_return\n\nEnsure build_row_from_header() handles the new field if it exists in the sheet header.",
        "testStrategy": "Update tests/test_add_album.py:\n- Verify spotify_album_id is present in returned dict\n- Verify it matches the expected 22-character ID\n- Test with existing URLs in test suite",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T03:35:54.224Z"
      },
      {
        "id": "5",
        "title": "Implement Logging Infrastructure",
        "description": "Add Python logging module configuration for structured logging to stdout (Railway compatible)",
        "details": "Create src/logging_config.py:\n\nimport logging\nimport sys\nfrom datetime import datetime\n\ndef setup_logging(level=logging.INFO):\n    \"\"\"Configure structured logging to stdout.\"\"\"\n    logger = logging.getLogger('aotw')\n    logger.setLevel(level)\n    \n    handler = logging.StreamHandler(sys.stdout)\n    handler.setLevel(level)\n    \n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S'\n    )\n    handler.setFormatter(formatter)\n    \n    logger.addHandler(handler)\n    return logger\n\n# Usage pattern:\nlogger = setup_logging()\nlogger.info('Message received', extra={'user_id': 123, 'url': url})\nlogger.error('Spotify lookup failed', extra={'url': url, 'error': str(e)})\n\nIntegrate into add_album.py, replacing print() statements:\n- Log Spotify API calls (URL, latency, success/error)\n- Log sheet operations (append success/error, row number)\n- Never log credentials or tokens",
        "testStrategy": "Manual verification:\n- Run existing add_album.py and verify structured log output\n- Check that errors are logged with context\n- Verify no secrets appear in logs (mock with fake credentials)",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T03:38:05.563Z"
      },
      {
        "id": "6",
        "title": "Create Telegram Bot Core with python-telegram-bot",
        "description": "Implement the Telegram bot using python-telegram-bot library with polling mode, message pattern matching, and chat ID whitelisting",
        "details": "Create src/telegram_bot.py:\n\nimport os\nimport re\nfrom telegram import Update\nfrom telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes\nfrom logging_config import setup_logging\nfrom validation import is_valid_spotify_album_url\n\nlogger = setup_logging()\n\nALLOWED_CHAT_ID = os.getenv('TELEGRAM_ALLOWED_CHAT_ID')  # Set in Railway env\nBOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')\n\nasync def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n    \"\"\"Handle incoming messages.\"\"\"\n    chat_id = update.effective_chat.id\n    \n    # Whitelist check\n    if str(chat_id) != ALLOWED_CHAT_ID:\n        logger.warning(f'Ignored message from unauthorized chat: {chat_id}')\n        return\n    \n    message_text = update.message.text\n    logger.info(f'Message received from {update.effective_user.username}: {message_text}')\n    \n    # Pattern match: @aotw <spotify_url>\n    pattern = r'@aotw\\s+(https://open\\.spotify\\.com/album/[^\\s]+)'\n    match = re.search(pattern, message_text, re.IGNORECASE)\n    \n    if not match:\n        return  # Not a trigger message, ignore silently\n    \n    url = match.group(1)\n    \n    # URL validation\n    if not is_valid_spotify_album_url(url):\n        await update.message.reply_text(\n            \"âŒ Invalid Spotify album link. Please post a valid album URL.\"\n        )\n        return\n    \n    # Trigger pipeline (will be implemented in next task)\n    try:\n        from pipeline import process_album\n        result = await process_album(url)\n        await update.message.reply_text(result['message'])\n    except Exception as e:\n        logger.error(f'Pipeline failed: {e}', exc_info=True)\n        await update.message.reply_text(\n            \"âŒ Something went wrong. Please try again later.\"\n        )\n\ndef main():\n    if not BOT_TOKEN:\n        raise ValueError('TELEGRAM_BOT_TOKEN not set')\n    if not ALLOWED_CHAT_ID:\n        raise ValueError('TELEGRAM_ALLOWED_CHAT_ID not set')\n    \n    app = ApplicationBuilder().token(BOT_TOKEN).build()\n    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n    \n    logger.info('Bot starting in polling mode...')\n    app.run_polling()\n\nif __name__ == '__main__':\n    main()\n\nUpdate environment.yml to include python-telegram-bot>=20.0.",
        "testStrategy": "Integration tests:\n- Mock telegram Update objects with various message patterns\n- Test whitelist enforcement (authorized and unauthorized chat IDs)\n- Test pattern matching (@aotw with URL, without URL, wrong format)\n- Test URL validation integration\n- Manual test: Deploy to test environment and send messages",
        "priority": "high",
        "dependencies": [
          "2",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-25T04:15:02.914Z"
      },
      {
        "id": "7",
        "title": "Refactor add_album.py into Pipeline Module",
        "description": "Create a unified pipeline module that orchestrates validation, deduplication, Spotify lookup, sheet append, and returns structured results",
        "details": "Create src/pipeline.py:\n\nfrom typing import Dict\nfrom datetime import datetime\nimport time\nfrom logging_config import setup_logging\nfrom validation import (\n    is_valid_spotify_album_url,\n    extract_spotify_album_id,\n    validate_album_metadata\n)\nfrom add_album import (\n    get_spotify_api,\n    get_album_info,\n    get_google_sheet,\n    get_header_row_and_map,\n    find_header_cells,\n    get_next_pick_number_and_date,\n    build_row_from_header,\n    check_duplicate\n)\n\nlogger = setup_logging()\n\nasync def process_album(url: str, sheet_id=None, sheet_tab=None, creds_path=None) -> Dict:\n    \"\"\"Main pipeline orchestrator.\n    Returns: {'success': bool, 'message': str, 'data': dict}\n    \"\"\"\n    start_time = time.time()\n    \n    # Step 1: URL validation\n    if not is_valid_spotify_album_url(url):\n        logger.warning(f'Invalid URL format: {url}')\n        return {\n            'success': False,\n            'message': \"âŒ Invalid Spotify album link. Please post a valid album URL.\"\n        }\n    \n    album_id = extract_spotify_album_id(url)\n    logger.info(f'Processing album: {album_id}')\n    \n    # Step 2: Get Google Sheet for dedup check\n    try:\n        worksheet = get_google_sheet(sheet_id, sheet_tab, creds_path)\n    except Exception as e:\n        logger.error(f'Sheet access failed: {e}')\n        return {\n            'success': False,\n            'message': \"âŒ Failed to access Google Sheet. Please try again later.\"\n        }\n    \n    # Step 3: Deduplication check\n    is_duplicate, dup_message = check_duplicate(url, worksheet)\n    if is_duplicate:\n        logger.info(f'Duplicate detected: {album_id} - {dup_message}')\n        return {\n            'success': False,\n            'message': f\"âŒ {dup_message}\"\n        }\n    \n    # Step 4: Fetch Spotify metadata\n    try:\n        sp = get_spotify_api()\n        album_info = get_album_info(url=url, spot_api=sp)\n        spotify_latency = time.time() - start_time\n        logger.info(f'Spotify lookup succeeded in {spotify_latency:.2f}s')\n    except Exception as e:\n        logger.error(f'Spotify lookup failed: {e}')\n        return {\n            'success': False,\n            'message': \"âŒ Couldn't fetch album info from Spotify. Please try again.\"\n        }\n    \n    if not album_info:\n        return {\n            'success': False,\n            'message': \"âŒ Invalid album URL or missing album data.\"\n        }\n    \n    # Step 5: Validate metadata\n    is_valid, validation_error = validate_album_metadata(album_info)\n    if not is_valid:\n        logger.error(f'Metadata validation failed: {validation_error}')\n        return {\n            'success': False,\n            'message': f\"âŒ {validation_error}\"\n        }\n    \n    # Step 6: Append to Google Sheet (pick # will be auto-filled by formula)\n    try:\n        header_row, header_map = get_header_row_and_map(worksheet)\n        pick_cell, date_cell = find_header_cells(worksheet)\n        next_pick, next_date = get_next_pick_number_and_date(\n            worksheet, header_row, pick_cell.col, date_cell.col\n        )\n        \n        # Build row WITHOUT pick number (formula will fill it)\n        row = build_row_from_header(header_map, '', next_date, album_info)\n        worksheet.append_row(row, value_input_option='USER_ENTERED')\n        \n        logger.info(f'Sheet append succeeded: row {header_row + len(worksheet.col_values(1))}')\n    except Exception as e:\n        logger.error(f'Sheet append failed: {e}')\n        return {\n            'success': False,\n            'message': \"âŒ Failed to add album to sheet. Please try again.\"\n        }\n    \n    # Step 7: Return success\n    artist = album_info.get('Artist', 'Unknown')\n    album_name = album_info.get('Album', 'Unknown')\n    # We'll read pick number from the sheet after formula fills it\n    return {\n        'success': True,\n        'message': f\"âœ… Added *{album_name}* by *{artist}*\",\n        'data': album_info\n    }\n\nThis replaces the existing add_album() logic with better error handling and structured returns.",
        "testStrategy": "Integration tests:\n- Mock all external calls (Spotify, Google Sheets)\n- Test full pipeline with valid album\n- Test each failure point (invalid URL, duplicate, Spotify error, sheet error)\n- Verify correct error messages returned\n- Verify logging output at each step",
        "priority": "high",
        "dependencies": [
          "3",
          "4",
          "5"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "8",
        "title": "Implement Retry Logic for External API Calls",
        "description": "Create a decorator for retrying Spotify and Google Sheets API calls with exponential backoff",
        "details": "Create src/retry_utils.py:\n\nimport time\nimport functools\nfrom typing import Callable, Type\nfrom logging_config import setup_logging\n\nlogger = setup_logging()\n\ndef retry_with_backoff(\n    max_attempts=3,\n    base_delay=1.0,\n    exponential_base=2,\n    exceptions=(Exception,)\n):\n    \"\"\"Retry decorator with exponential backoff.\n    \n    Args:\n        max_attempts: Max number of tries (default 3)\n        base_delay: Initial delay in seconds (default 1.0)\n        exponential_base: Backoff multiplier (default 2)\n        exceptions: Tuple of exceptions to catch (default all)\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(1, max_attempts + 1):\n                try:\n                    return func(*args, **kwargs)\n                except exceptions as e:\n                    if attempt == max_attempts:\n                        logger.error(\n                            f'{func.__name__} failed after {max_attempts} attempts: {e}'\n                        )\n                        raise\n                    \n                    delay = base_delay * (exponential_base ** (attempt - 1))\n                    logger.warning(\n                        f'{func.__name__} attempt {attempt} failed: {e}. '\n                        f'Retrying in {delay:.1f}s...'\n                    )\n                    time.sleep(delay)\n            return None\n        return wrapper\n    return decorator\n\n# Usage:\nfrom gspread.exceptions import GSpreadException\nfrom spotipy.exceptions import SpotifyException\n\n@retry_with_backoff(max_attempts=3, exceptions=(GSpreadException, SpotifyException))\ndef get_spotify_api_with_retry():\n    return get_spotify_api()\n\n@retry_with_backoff(max_attempts=3, exceptions=(GSpreadException,))\ndef append_to_sheet_with_retry(worksheet, row):\n    return worksheet.append_row(row, value_input_option='USER_ENTERED')\n\nIntegrate into pipeline.py for Spotify and Sheet operations.",
        "testStrategy": "Unit tests:\n- Test successful call on first attempt\n- Test retry after transient failure\n- Test all retries exhausted (raises exception)\n- Test exponential backoff timing\n- Mock external calls to simulate failures",
        "priority": "medium",
        "dependencies": [
          "7"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "9",
        "title": "Create JSON Export Functionality",
        "description": "Implement function to read full Google Sheet and generate data.json with normalized fields (spotify_album_id, pick_number, picked_at as ISO date)",
        "details": "Create src/export_json.py:\n\nimport json\nfrom datetime import datetime\nfrom typing import List, Dict\nfrom logging_config import setup_logging\nfrom add_album import (\n    get_google_sheet,\n    get_header_row_and_map,\n    parse_sheet_date\n)\nfrom validation import extract_spotify_album_id\n\nlogger = setup_logging()\n\ndef export_sheet_to_json(\n    sheet_id=None,\n    sheet_tab=None,\n    creds_path=None,\n    output_path='data.json'\n) -> List[Dict]:\n    \"\"\"Read Google Sheet and generate data.json.\n    \n    Returns list of albums with fields:\n    - spotify_album_id (string)\n    - pick_number (int)\n    - picked_at (ISO date string YYYY-MM-DD)\n    - artist, album, year, artwork_url, spotify_url, picker\n    \"\"\"\n    worksheet = get_google_sheet(sheet_id, sheet_tab, creds_path)\n    header_row, header_map = get_header_row_and_map(worksheet)\n    \n    # Get all rows\n    all_values = worksheet.get_all_values()\n    data_rows = all_values[header_row:]  # Skip header\n    \n    albums = []\n    for row in data_rows:\n        if not row or not any(row):  # Skip empty rows\n            continue\n        \n        # Build album dict\n        album = {}\n        \n        # Extract fields by header index\n        for header_name, col_idx in header_map.items():\n            if col_idx < len(row):\n                value = row[col_idx].strip()\n                album[header_name] = value\n        \n        # Extract album ID from URL\n        spotify_url = album.get('spotify_album_url', '')\n        album_id = extract_spotify_album_id(spotify_url)\n        if not album_id:\n            logger.warning(f'Skipping row with invalid Spotify URL: {spotify_url}')\n            continue\n        \n        # Normalize fields\n        try:\n            pick_number = int(float(album.get('pick', 0)))\n        except (ValueError, TypeError):\n            pick_number = 0\n        \n        # Normalize date to ISO format\n        date_value = album.get('date', '')\n        parsed_date = parse_sheet_date(date_value)\n        picked_at = parsed_date.isoformat() if parsed_date else ''\n        \n        # Build final record\n        normalized = {\n            'spotify_album_id': album_id,\n            'pick_number': pick_number,\n            'picked_at': picked_at,\n            'artist': album.get('artist', ''),\n            'album': album.get('album', ''),\n            'year': album.get('year', ''),\n            'artwork_url': album.get('artwork_url', ''),\n            'spotify_url': spotify_url,\n            'picker': album.get('picker', '')\n        }\n        \n        albums.append(normalized)\n    \n    # Sort by pick number\n    albums.sort(key=lambda x: x['pick_number'])\n    \n    # Write to file\n    with open(output_path, 'w', encoding='utf-8') as f:\n        json.dump(albums, f, indent=2, ensure_ascii=False)\n    \n    logger.info(f'Exported {len(albums)} albums to {output_path}')\n    return albums\n\nif __name__ == '__main__':\n    # CLI usage for testing\n    export_sheet_to_json()",
        "testStrategy": "Integration tests:\n- Mock worksheet.get_all_values() with sample data\n- Test normalization (dates, pick numbers, album IDs)\n- Test skipping invalid rows (missing URLs, bad dates)\n- Test sorting by pick number\n- Verify JSON output structure\n- Test with empty sheet",
        "priority": "high",
        "dependencies": [
          "2",
          "4"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "10",
        "title": "Implement GitHub API Integration for data.json Push",
        "description": "Create module to push data.json to GitHub repo via REST API with retry logic",
        "details": "Create src/github_push.py:\n\nimport os\nimport base64\nimport requests\nfrom typing import Optional\nfrom logging_config import setup_logging\nfrom retry_utils import retry_with_backoff\n\nlogger = setup_logging()\n\nGITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\nGITHUB_REPO_OWNER = os.getenv('GITHUB_REPO_OWNER')  # e.g., 'username'\nGITHUB_REPO_NAME = os.getenv('GITHUB_REPO_NAME')    # e.g., 'aotw-website'\nGITHUB_FILE_PATH = 'data.json'  # Path in repo\nGITHUB_BRANCH = 'main'\n\n@retry_with_backoff(\n    max_attempts=3,\n    base_delay=2.0,\n    exceptions=(requests.exceptions.RequestException,)\n)\ndef push_data_to_github(json_content: str, commit_message: str) -> bool:\n    \"\"\"Push data.json to GitHub via REST API.\n    \n    Args:\n        json_content: JSON string to write\n        commit_message: Git commit message\n    \n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    if not all([GITHUB_TOKEN, GITHUB_REPO_OWNER, GITHUB_REPO_NAME]):\n        raise ValueError('GitHub config incomplete. Set GITHUB_TOKEN, GITHUB_REPO_OWNER, GITHUB_REPO_NAME')\n    \n    api_url = f'https://api.github.com/repos/{GITHUB_REPO_OWNER}/{GITHUB_REPO_NAME}/contents/{GITHUB_FILE_PATH}'\n    \n    headers = {\n        'Authorization': f'token {GITHUB_TOKEN}',\n        'Accept': 'application/vnd.github.v3+json'\n    }\n    \n    # Get current file SHA (required for updates)\n    logger.info(f'Fetching current {GITHUB_FILE_PATH} from GitHub...')\n    response = requests.get(api_url, headers=headers, params={'ref': GITHUB_BRANCH})\n    \n    current_sha = None\n    if response.status_code == 200:\n        current_sha = response.json()['sha']\n        logger.info(f'Found existing file with SHA: {current_sha[:7]}')\n    elif response.status_code == 404:\n        logger.info('File does not exist, will create new')\n    else:\n        response.raise_for_status()\n    \n    # Encode content to base64\n    content_base64 = base64.b64encode(json_content.encode('utf-8')).decode('utf-8')\n    \n    # Prepare commit data\n    data = {\n        'message': commit_message,\n        'content': content_base64,\n        'branch': GITHUB_BRANCH\n    }\n    if current_sha:\n        data['sha'] = current_sha\n    \n    # Push to GitHub\n    logger.info(f'Pushing {GITHUB_FILE_PATH} to GitHub...')\n    response = requests.put(api_url, headers=headers, json=data)\n    \n    if response.status_code in (200, 201):\n        commit_sha = response.json()['commit']['sha']\n        logger.info(f'Successfully pushed to GitHub. Commit: {commit_sha[:7]}')\n        return True\n    else:\n        logger.error(f'GitHub push failed: {response.status_code} - {response.text}')\n        response.raise_for_status()\n        return False\n\ndef export_and_push(\n    sheet_id=None,\n    sheet_tab=None,\n    creds_path=None,\n    album_info=None\n) -> tuple[bool, str]:\n    \"\"\"Export sheet to JSON and push to GitHub.\n    \n    Returns: (success, message)\n    \"\"\"\n    try:\n        from export_json import export_sheet_to_json\n        \n        # Generate JSON\n        albums = export_sheet_to_json(sheet_id, sheet_tab, creds_path, output_path='/tmp/data.json')\n        \n        with open('/tmp/data.json', 'r') as f:\n            json_content = f.read()\n        \n        # Create commit message\n        if album_info:\n            artist = album_info.get('Artist', 'Unknown')\n            album_name = album_info.get('Album', 'Unknown')\n            commit_msg = f\"Add {artist} - {album_name}\"\n        else:\n            commit_msg = \"Update album data\"\n        \n        # Push to GitHub\n        success = push_data_to_github(json_content, commit_msg)\n        \n        if success:\n            return True, \"Website will update shortly\"\n        else:\n            return False, \"GitHub push failed, will sync on next run\"\n    \n    except Exception as e:\n        logger.error(f'Export and push failed: {e}', exc_info=True)\n        return False, \"Website update pending (will sync on next run)\"\n\nUpdate environment.yml to include requests if not present.",
        "testStrategy": "Integration tests:\n- Mock requests.get() and requests.put()\n- Test creating new file (404 response)\n- Test updating existing file (200 response with SHA)\n- Test retry on transient failures (429, 500)\n- Test all retries exhausted\n- Manual test: Create test repo and push data\n- Verify commit appears on GitHub",
        "priority": "high",
        "dependencies": [
          "8",
          "9"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "11",
        "title": "Integrate GitHub Push into Pipeline with Partial Failure Handling",
        "description": "Update pipeline.py to call GitHub push after sheet append, with graceful handling if GitHub fails but sheet succeeds",
        "details": "Update src/pipeline.py process_album() function:\n\nAfter Step 6 (sheet append succeeds), add:\n\n    # Step 7: Export to JSON and push to GitHub\n    github_success, github_message = export_and_push(\n        sheet_id=sheet_id,\n        sheet_tab=sheet_tab,\n        creds_path=creds_path,\n        album_info=album_info\n    )\n    \n    if not github_success:\n        logger.warning(f'GitHub push failed but sheet updated: {github_message}')\n        return {\n            'success': True,  # Sheet write succeeded\n            'message': (\n                f\"âœ… Added *{album_name}* by *{artist}* to sheet.\\n\"\n                f\"âš ï¸ {github_message}\"\n            ),\n            'data': album_info,\n            'partial_failure': True\n        }\n    \n    # Full success\n    return {\n        'success': True,\n        'message': (\n            f\"âœ… Added *{album_name}* by *{artist}*.\\n\"\n            f\"ðŸŒ {github_message}\"\n        ),\n        'data': album_info\n    }\n\nThis ensures:\n- Sheet is source of truth (if sheet succeeds but GitHub fails, data is safe)\n- User is informed of partial failure\n- Next successful run will regenerate JSON from full sheet, self-healing",
        "testStrategy": "Integration tests:\n- Mock sheet append success + GitHub success\n- Mock sheet append success + GitHub failure\n- Verify correct return messages\n- Verify partial_failure flag set correctly\n- Test self-healing: Run export_and_push() standalone after partial failure",
        "priority": "high",
        "dependencies": [
          "7",
          "10"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "12",
        "title": "Update Telegram Bot to Use New Pipeline",
        "description": "Integrate the pipeline module into the Telegram bot message handler",
        "details": "Update src/telegram_bot.py handle_message():\n\nReplace the placeholder pipeline call with:\n\n    # Trigger pipeline\n    try:\n        from pipeline import process_album\n        \n        logger.info(f'Triggering pipeline for {url}')\n        result = await process_album(\n            url,\n            sheet_id=os.getenv('GOOGLE_SHEET_ID'),\n            sheet_tab=os.getenv('GOOGLE_SHEET_TAB'),\n            creds_path=os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')\n        )\n        \n        # Reply with result message\n        await update.message.reply_text(\n            result['message'],\n            parse_mode='Markdown'\n        )\n        \n        if result['success']:\n            logger.info(f\"Pipeline succeeded: {result['data']}\")\n        else:\n            logger.warning(f\"Pipeline failed: {result['message']}\")\n    \n    except Exception as e:\n        logger.error(f'Pipeline crashed: {e}', exc_info=True)\n        await update.message.reply_text(\n            \"âŒ Something went wrong. Please try again later.\"\n        )\n\nEnsure GOOGLE_SERVICE_ACCOUNT_JSON env var can be either:\n1. Path to JSON file\n2. JSON content as string (Railway supports large env vars)\n\nUpdate get_google_sheet() to handle both.",
        "testStrategy": "Integration tests:\n- Mock process_album() with various results\n- Test success reply message\n- Test failure reply messages\n- Test partial failure message\n- Test exception handling\n- Manual test: Send message to bot and verify reply",
        "priority": "high",
        "dependencies": [
          "6",
          "11"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "13",
        "title": "Create Railway Deployment Configuration",
        "description": "Create Railway configuration files and document environment variables needed for bot deployment",
        "details": "Create railway.json (or use Railway web UI):\n\n{\n  \"build\": {\n    \"builder\": \"NIXPACKS\"\n  },\n  \"deploy\": {\n    \"startCommand\": \"python src/telegram_bot.py\",\n    \"healthcheckPath\": null,\n    \"restartPolicyType\": \"ON_FAILURE\"\n  }\n}\n\nCreate Procfile (alternative):\nworker: python src/telegram_bot.py\n\nCreate requirements.txt from environment.yml:\nspotipy>=2.23.0\ngspread>=5.10.0\npython-telegram-bot>=20.0\nrequests>=2.31.0\n\nCreate DEPLOYMENT.md documenting all required env vars:\n\n# Railway Environment Variables\n\n## Required Secrets\n1. TELEGRAM_BOT_TOKEN - from @BotFather\n2. TELEGRAM_ALLOWED_CHAT_ID - Telegram group chat ID (get via bot log or @RawDataBot)\n3. SPOTIFY_CLIENT_ID - from Spotify Developer Dashboard\n4. SPOTIFY_CLIENT_SECRET - from Spotify Developer Dashboard\n5. GOOGLE_SHEET_ID - from sheet URL\n6. GOOGLE_SHEET_TAB - sheet tab name (default: 'Sheet1')\n7. GOOGLE_SERVICE_ACCOUNT_JSON - full JSON content of service account key\n8. GITHUB_TOKEN - fine-grained PAT with Contents:write for website repo\n9. GITHUB_REPO_OWNER - GitHub username\n10. GITHUB_REPO_NAME - website repo name\n\n## Setup Steps\n1. Create Railway account and connect GitHub repo\n2. Create new project from repo\n3. Add all environment variables in Railway dashboard\n4. Deploy\n5. Monitor logs for startup\n\n## Testing Deployment\n1. Send test message: `@aotw https://open.spotify.com/album/...`\n2. Check Railway logs for pipeline execution\n3. Verify sheet updated\n4. Verify GitHub commit created\n5. Verify Netlify deployed\n\nUpdate get_spotify_api() to read from env vars:\n\ndef get_spotify_api():\n    CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')\n    CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')\n    \n    if not CLIENT_ID:\n        # Fallback to file for local dev\n        credentials_file = \"spotify_credentials.json\"\n        # ... existing file logic ...\n    else:\n        auth_manager = SpotifyClientCredentials(\n            client_id=CLIENT_ID,\n            client_secret=CLIENT_SECRET\n        )\n        sp = spotipy.Spotify(auth_manager=auth_manager)\n        return sp\n\nUpdate get_google_sheet() to handle JSON content as string:\n\ndef get_google_sheet(sheet_id=None, sheet_tab=None, creds_path=None):\n    sheet_id = sheet_id or os.getenv('GOOGLE_SHEET_ID') or '1h1uDCZPqJovFfUKPzfPgUwUOHjFdCXHWVhUE6VvFA_s'\n    sheet_tab = sheet_tab or os.getenv('GOOGLE_SHEET_TAB', 'Sheet1')\n    \n    # Check if env var is JSON content (not path)\n    service_account_json = os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')\n    if service_account_json and service_account_json.startswith('{'):\n        # It's JSON content\n        import json\n        import tempfile\n        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:\n            f.write(service_account_json)\n            temp_path = f.name\n        gc = gspread.service_account(filename=temp_path)\n        os.unlink(temp_path)\n    else:\n        # It's a file path or use default\n        creds_path = creds_path or service_account_json or get_default_creds_path()\n        gc = gspread.service_account(filename=creds_path)\n    \n    sheet = gc.open_by_key(sheet_id)\n    worksheet = sheet.worksheet(sheet_tab)\n    return worksheet",
        "testStrategy": "Deployment validation:\n- Test Railway build succeeds\n- Test bot starts and polls\n- Test all env vars loaded correctly\n- Test credentials work (Spotify, Sheets, GitHub)\n- Monitor logs for errors\n- Send test album and verify end-to-end flow",
        "priority": "high",
        "dependencies": [
          "12"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "14",
        "title": "Create React + Vite Website Frontend Scaffold",
        "description": "Initialize a React + Vite project for the public-facing website with basic structure",
        "details": "Create website/ directory:\n\ncd website/\nnpm create vite@latest . -- --template react\nnpm install\n\nProject structure:\nwebsite/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ App.jsx\nâ”‚   â”œâ”€â”€ components/\nâ”‚   â”‚   â”œâ”€â”€ AlbumGrid.jsx\nâ”‚   â”‚   â”œâ”€â”€ AlbumCard.jsx\nâ”‚   â”‚   â”œâ”€â”€ SearchBar.jsx\nâ”‚   â”‚   â””â”€â”€ FilterBar.jsx\nâ”‚   â”œâ”€â”€ hooks/\nâ”‚   â”‚   â””â”€â”€ useAlbums.js\nâ”‚   â”œâ”€â”€ utils/\nâ”‚   â”‚   â””â”€â”€ filterSort.js\nâ”‚   â”œâ”€â”€ styles/\nâ”‚   â”‚   â””â”€â”€ index.css\nâ”‚   â””â”€â”€ main.jsx\nâ”œâ”€â”€ public/\nâ”‚   â””â”€â”€ data.json (generated, will be in root for Netlify)\nâ”œâ”€â”€ index.html\nâ”œâ”€â”€ vite.config.js\nâ””â”€â”€ package.json\n\nConfigure vite.config.js:\n\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  build: {\n    outDir: 'dist',\n    assetsDir: 'assets'\n  }\n})\n\nCreate basic App.jsx:\n\nimport { useState, useEffect } from 'react'\nimport AlbumGrid from './components/AlbumGrid'\nimport SearchBar from './components/SearchBar'\nimport FilterBar from './components/FilterBar'\nimport './styles/index.css'\n\nfunction App() {\n  const [albums, setAlbums] = useState([])\n  const [loading, setLoading] = useState(true)\n  const [searchTerm, setSearchTerm] = useState('')\n  const [filters, setFilters] = useState({})\n  \n  useEffect(() => {\n    fetch('/data.json')\n      .then(res => res.json())\n      .then(data => {\n        setAlbums(data)\n        setLoading(false)\n      })\n      .catch(err => {\n        console.error('Failed to load albums:', err)\n        setLoading(false)\n      })\n  }, [])\n  \n  if (loading) return <div className=\"loading\">Loading albums...</div>\n  \n  return (\n    <div className=\"app\">\n      <header>\n        <h1>Album of the Week</h1>\n        <SearchBar value={searchTerm} onChange={setSearchTerm} />\n        <FilterBar filters={filters} onChange={setFilters} />\n      </header>\n      <main>\n        <AlbumGrid \n          albums={albums} \n          searchTerm={searchTerm}\n          filters={filters}\n        />\n      </main>\n    </div>\n  )\n}\n\nexport default App\n\nCreate .gitignore:\nnode_modules/\ndist/\n.env\n*.log",
        "testStrategy": "Local development:\n- Run `npm run dev` and verify site loads\n- Place sample data.json in public/ with test data\n- Verify albums load and display\n- Test hot reload works\n- Build production bundle: `npm run build`\n- Verify dist/ contains optimized assets",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "15",
        "title": "Implement Album Data Fetching Hook",
        "description": "Create custom React hook to fetch and manage album data from data.json",
        "details": "Create src/hooks/useAlbums.js:\n\nimport { useState, useEffect } from 'react'\n\nexport function useAlbums() {\n  const [albums, setAlbums] = useState([])\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState(null)\n  \n  useEffect(() => {\n    fetch('/data.json')\n      .then(response => {\n        if (!response.ok) {\n          throw new Error('Failed to fetch albums')\n        }\n        return response.json()\n      })\n      .then(data => {\n        setAlbums(data)\n        setLoading(false)\n      })\n      .catch(err => {\n        console.error('Error loading albums:', err)\n        setError(err.message)\n        setLoading(false)\n      })\n  }, [])\n  \n  return { albums, loading, error }\n}\n\n// Computed values for filters\nexport function useAlbumMetadata(albums) {\n  const years = [...new Set(albums.map(a => a.year))].sort((a, b) => b - a)\n  const artists = [...new Set(albums.map(a => a.artist))].sort()\n  const pickers = [...new Set(albums.map(a => a.picker).filter(Boolean))].sort()\n  \n  return { years, artists, pickers }\n}\n\nUpdate App.jsx to use the hook:\n\nimport { useAlbums, useAlbumMetadata } from './hooks/useAlbums'\n\nfunction App() {\n  const { albums, loading, error } = useAlbums()\n  const metadata = useAlbumMetadata(albums)\n  // ... rest of component",
        "testStrategy": "Unit tests with React Testing Library:\n- Mock fetch() with sample data\n- Test successful data load\n- Test loading state\n- Test error state\n- Test metadata extraction (years, artists, pickers)\n- Verify no duplicate fetch on re-render",
        "priority": "medium",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "16",
        "title": "Implement Search and Filter Utilities",
        "description": "Create utility functions for searching, filtering, and sorting albums client-side",
        "details": "Create src/utils/filterSort.js:\n\n/**\n * Search albums by artist, album name, or year\n * Case-insensitive, searches across multiple fields\n */\nexport function searchAlbums(albums, searchTerm) {\n  if (!searchTerm) return albums\n  \n  const term = searchTerm.toLowerCase()\n  return albums.filter(album => \n    album.artist?.toLowerCase().includes(term) ||\n    album.album?.toLowerCase().includes(term) ||\n    album.year?.toString().includes(term) ||\n    album.picker?.toLowerCase().includes(term)\n  )\n}\n\n/**\n * Filter albums by year, artist, or picker\n * filters: { year: '2020', artist: 'Radiohead', picker: 'Dave' }\n */\nexport function filterAlbums(albums, filters) {\n  let filtered = albums\n  \n  if (filters.year) {\n    filtered = filtered.filter(a => a.year === filters.year)\n  }\n  \n  if (filters.artist) {\n    filtered = filtered.filter(a => a.artist === filters.artist)\n  }\n  \n  if (filters.picker) {\n    filtered = filtered.filter(a => a.picker === filters.picker)\n  }\n  \n  return filtered\n}\n\n/**\n * Sort albums by field\n * sortBy: 'date' | 'artist' | 'album' | 'year' | 'picker'\n * direction: 'asc' | 'desc'\n */\nexport function sortAlbums(albums, sortBy = 'date', direction = 'desc') {\n  const sorted = [...albums]\n  \n  const compareFn = (a, b) => {\n    let aVal, bVal\n    \n    switch (sortBy) {\n      case 'date':\n        aVal = a.picked_at || ''\n        bVal = b.picked_at || ''\n        break\n      case 'artist':\n        aVal = a.artist?.toLowerCase() || ''\n        bVal = b.artist?.toLowerCase() || ''\n        break\n      case 'album':\n        aVal = a.album?.toLowerCase() || ''\n        bVal = b.album?.toLowerCase() || ''\n        break\n      case 'year':\n        aVal = parseInt(a.year) || 0\n        bVal = parseInt(b.year) || 0\n        break\n      case 'picker':\n        aVal = a.picker?.toLowerCase() || ''\n        bVal = b.picker?.toLowerCase() || ''\n        break\n      default:\n        aVal = a.pick_number || 0\n        bVal = b.pick_number || 0\n    }\n    \n    if (aVal < bVal) return direction === 'asc' ? -1 : 1\n    if (aVal > bVal) return direction === 'asc' ? 1 : -1\n    return 0\n  }\n  \n  return sorted.sort(compareFn)\n}\n\n/**\n * Paginate albums by year (for performance)\n * Returns object: { [year]: [albums...] }\n */\nexport function groupByYear(albums) {\n  const grouped = {}\n  albums.forEach(album => {\n    const year = album.year || 'Unknown'\n    if (!grouped[year]) {\n      grouped[year] = []\n    }\n    grouped[year].push(album)\n  })\n  return grouped\n}\n\n/**\n * Apply all filters, search, and sort\n */\nexport function processAlbums(albums, { searchTerm, filters, sortBy, direction }) {\n  let processed = albums\n  processed = searchAlbums(processed, searchTerm)\n  processed = filterAlbums(processed, filters)\n  processed = sortAlbums(processed, sortBy, direction)\n  return processed\n}",
        "testStrategy": "Unit tests:\n- Test search with various terms (artist, album, year)\n- Test search case-insensitivity\n- Test filter by year, artist, picker\n- Test combined filters\n- Test sort by each field (asc/desc)\n- Test groupByYear with mixed years\n- Test processAlbums with all options combined",
        "priority": "medium",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "17",
        "title": "Build AlbumCard Component",
        "description": "Create the individual album card component displaying artwork, artist, album, year, date, and picker with click to open Spotify",
        "details": "Create src/components/AlbumCard.jsx:\n\nimport { useState } from 'react'\nimport './AlbumCard.css'\n\nfunction AlbumCard({ album }) {\n  const [imageError, setImageError] = useState(false)\n  \n  const handleClick = () => {\n    window.open(album.spotify_url, '_blank', 'noopener,noreferrer')\n  }\n  \n  const formatDate = (isoDate) => {\n    if (!isoDate) return ''\n    const date = new Date(isoDate)\n    return date.toLocaleDateString('en-US', { \n      month: 'short', \n      day: 'numeric', \n      year: 'numeric' \n    })\n  }\n  \n  return (\n    <div className=\"album-card\" onClick={handleClick}>\n      <div className=\"album-artwork\">\n        {!imageError ? (\n          <img \n            src={album.artwork_url} \n            alt={`${album.album} by ${album.artist}`}\n            onError={() => setImageError(true)}\n            loading=\"lazy\"\n          />\n        ) : (\n          <div className=\"artwork-placeholder\">\n            <span>ðŸŽµ</span>\n          </div>\n        )}\n      </div>\n      \n      <div className=\"album-info\">\n        <h3 className=\"album-title\">{album.album}</h3>\n        <p className=\"album-artist\">{album.artist}</p>\n        \n        <div className=\"album-meta\">\n          <span className=\"album-year\">{album.year}</span>\n          {album.picker && (\n            <span className=\"album-picker\">by {album.picker}</span>\n          )}\n        </div>\n        \n        <div className=\"album-date\">\n          Pick #{album.pick_number} Â· {formatDate(album.picked_at)}\n        </div>\n      </div>\n    </div>\n  )\n}\n\nexport default AlbumCard\n\nCreate src/components/AlbumCard.css:\n\n.album-card {\n  background: var(--card-bg);\n  border-radius: 8px;\n  overflow: hidden;\n  cursor: pointer;\n  transition: transform 0.2s, box-shadow 0.2s;\n  display: flex;\n  flex-direction: column;\n}\n\n.album-card:hover {\n  transform: translateY(-4px);\n  box-shadow: 0 8px 16px rgba(0, 0, 0, 0.3);\n}\n\n.album-artwork {\n  aspect-ratio: 1;\n  overflow: hidden;\n  background: var(--artwork-bg);\n}\n\n.album-artwork img {\n  width: 100%;\n  height: 100%;\n  object-fit: cover;\n}\n\n.artwork-placeholder {\n  width: 100%;\n  height: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  font-size: 4rem;\n  opacity: 0.3;\n}\n\n.album-info {\n  padding: 1rem;\n  flex: 1;\n  display: flex;\n  flex-direction: column;\n  gap: 0.5rem;\n}\n\n.album-title {\n  font-size: 1rem;\n  font-weight: 600;\n  margin: 0;\n  overflow: hidden;\n  text-overflow: ellipsis;\n  display: -webkit-box;\n  -webkit-line-clamp: 2;\n  -webkit-box-orient: vertical;\n}\n\n.album-artist {\n  font-size: 0.9rem;\n  color: var(--text-secondary);\n  margin: 0;\n}\n\n.album-meta {\n  display: flex;\n  gap: 0.5rem;\n  font-size: 0.85rem;\n  color: var(--text-tertiary);\n}\n\n.album-date {\n  font-size: 0.8rem;\n  color: var(--text-tertiary);\n  margin-top: auto;\n}",
        "testStrategy": "Component tests:\n- Render with complete album data\n- Test click opens Spotify URL in new tab\n- Test image error fallback\n- Test date formatting\n- Test optional picker field\n- Visual regression test for layout\n- Test lazy loading attribute present",
        "priority": "high",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "18",
        "title": "Build AlbumGrid Component with Pagination",
        "description": "Create the grid layout component that renders album cards with year-based pagination or virtualization for performance",
        "details": "Create src/components/AlbumGrid.jsx:\n\nimport { useState, useMemo } from 'react'\nimport AlbumCard from './AlbumCard'\nimport { processAlbums, groupByYear } from '../utils/filterSort'\nimport './AlbumGrid.css'\n\nfunction AlbumGrid({ albums, searchTerm, filters, sortBy = 'date', direction = 'desc' }) {\n  const [expandedYears, setExpandedYears] = useState(new Set())\n  const [viewMode, setViewMode] = useState('grouped') // 'grouped' | 'all'\n  \n  // Process albums (filter, search, sort)\n  const processedAlbums = useMemo(() => {\n    return processAlbums(albums, { searchTerm, filters, sortBy, direction })\n  }, [albums, searchTerm, filters, sortBy, direction])\n  \n  // Group by year for performance\n  const albumsByYear = useMemo(() => {\n    return groupByYear(processedAlbums)\n  }, [processedAlbums])\n  \n  const years = Object.keys(albumsByYear).sort((a, b) => b - a)\n  \n  const toggleYear = (year) => {\n    const newExpanded = new Set(expandedYears)\n    if (newExpanded.has(year)) {\n      newExpanded.delete(year)\n    } else {\n      newExpanded.add(year)\n    }\n    setExpandedYears(newExpanded)\n  }\n  \n  const expandAll = () => {\n    setExpandedYears(new Set(years))\n  }\n  \n  const collapseAll = () => {\n    setExpandedYears(new Set())\n  }\n  \n  if (processedAlbums.length === 0) {\n    return (\n      <div className=\"empty-state\">\n        <p>No albums found</p>\n      </div>\n    )\n  }\n  \n  // View all mode (no grouping, for small result sets)\n  if (viewMode === 'all' || processedAlbums.length < 50) {\n    return (\n      <div className=\"album-grid-container\">\n        <div className=\"album-grid\">\n          {processedAlbums.map(album => (\n            <AlbumCard key={album.spotify_album_id} album={album} />\n          ))}\n        </div>\n      </div>\n    )\n  }\n  \n  // Grouped by year mode\n  return (\n    <div className=\"album-grid-container\">\n      <div className=\"grid-controls\">\n        <button onClick={expandAll}>Expand All</button>\n        <button onClick={collapseAll}>Collapse All</button>\n        <span>{processedAlbums.length} albums</span>\n      </div>\n      \n      {years.map(year => {\n        const yearAlbums = albumsByYear[year]\n        const isExpanded = expandedYears.has(year)\n        \n        return (\n          <div key={year} className=\"year-group\">\n            <div className=\"year-header\" onClick={() => toggleYear(year)}>\n              <h2>\n                <span className=\"expand-icon\">{isExpanded ? 'â–¼' : 'â–¶'}</span>\n                {year}\n                <span className=\"year-count\">({yearAlbums.length})</span>\n              </h2>\n            </div>\n            \n            {isExpanded && (\n              <div className=\"album-grid\">\n                {yearAlbums.map(album => (\n                  <AlbumCard key={album.spotify_album_id} album={album} />\n                ))}\n              </div>\n            )}\n          </div>\n        )\n      })}\n    </div>\n  )\n}\n\nexport default AlbumGrid\n\nCreate src/components/AlbumGrid.css:\n\n.album-grid-container {\n  width: 100%;\n  max-width: 1400px;\n  margin: 0 auto;\n  padding: 2rem 1rem;\n}\n\n.grid-controls {\n  display: flex;\n  gap: 1rem;\n  margin-bottom: 2rem;\n  align-items: center;\n}\n\n.grid-controls button {\n  padding: 0.5rem 1rem;\n  background: var(--button-bg);\n  border: none;\n  border-radius: 4px;\n  cursor: pointer;\n  color: var(--text-primary);\n}\n\n.grid-controls button:hover {\n  background: var(--button-hover);\n}\n\n.year-group {\n  margin-bottom: 2rem;\n}\n\n.year-header {\n  cursor: pointer;\n  margin-bottom: 1rem;\n  user-select: none;\n}\n\n.year-header h2 {\n  display: flex;\n  align-items: center;\n  gap: 0.5rem;\n  font-size: 1.5rem;\n  margin: 0;\n}\n\n.expand-icon {\n  font-size: 1rem;\n  color: var(--text-secondary);\n}\n\n.year-count {\n  font-size: 1rem;\n  color: var(--text-tertiary);\n  font-weight: normal;\n}\n\n.album-grid {\n  display: grid;\n  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));\n  gap: 1.5rem;\n}\n\n@media (max-width: 768px) {\n  .album-grid {\n    grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));\n    gap: 1rem;\n  }\n}\n\n.empty-state {\n  text-align: center;\n  padding: 4rem 1rem;\n  color: var(--text-secondary);\n}",
        "testStrategy": "Component tests:\n- Render with sample albums\n- Test year grouping logic\n- Test expand/collapse year sections\n- Test expand all / collapse all buttons\n- Test view mode switching\n- Test empty state\n- Test responsive grid layout\n- Performance test with 300+ albums",
        "priority": "high",
        "dependencies": [
          "16",
          "17"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "19",
        "title": "Build SearchBar Component",
        "description": "Create the search input component with real-time filtering",
        "details": "Create src/components/SearchBar.jsx:\n\nimport { useState, useEffect } from 'react'\nimport './SearchBar.css'\n\nfunction SearchBar({ value, onChange, placeholder = 'Search albums, artists, years...' }) {\n  const [localValue, setLocalValue] = useState(value)\n  \n  // Debounce search input\n  useEffect(() => {\n    const timer = setTimeout(() => {\n      onChange(localValue)\n    }, 300)\n    \n    return () => clearTimeout(timer)\n  }, [localValue, onChange])\n  \n  const handleClear = () => {\n    setLocalValue('')\n    onChange('')\n  }\n  \n  return (\n    <div className=\"search-bar\">\n      <input\n        type=\"text\"\n        value={localValue}\n        onChange={(e) => setLocalValue(e.target.value)}\n        placeholder={placeholder}\n        className=\"search-input\"\n      />\n      {localValue && (\n        <button \n          className=\"clear-button\" \n          onClick={handleClear}\n          aria-label=\"Clear search\"\n        >\n          âœ•\n        </button>\n      )}\n    </div>\n  )\n}\n\nexport default SearchBar\n\nCreate src/components/SearchBar.css:\n\n.search-bar {\n  position: relative;\n  width: 100%;\n  max-width: 600px;\n  margin: 1rem auto;\n}\n\n.search-input {\n  width: 100%;\n  padding: 0.75rem 2.5rem 0.75rem 1rem;\n  font-size: 1rem;\n  border: 2px solid var(--border-color);\n  border-radius: 8px;\n  background: var(--input-bg);\n  color: var(--text-primary);\n  transition: border-color 0.2s;\n}\n\n.search-input:focus {\n  outline: none;\n  border-color: var(--accent-color);\n}\n\n.clear-button {\n  position: absolute;\n  right: 0.5rem;\n  top: 50%;\n  transform: translateY(-50%);\n  background: none;\n  border: none;\n  font-size: 1.25rem;\n  cursor: pointer;\n  color: var(--text-secondary);\n  padding: 0.5rem;\n  line-height: 1;\n}\n\n.clear-button:hover {\n  color: var(--text-primary);\n}",
        "testStrategy": "Component tests:\n- Test input value changes\n- Test debounce (300ms delay)\n- Test clear button appears when text entered\n- Test clear button clears input and calls onChange\n- Test placeholder text\n- Accessibility test (aria labels, keyboard navigation)",
        "priority": "medium",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "20",
        "title": "Build FilterBar Component",
        "description": "Create the filter controls for year, artist, picker, and sort options",
        "details": "Create src/components/FilterBar.jsx:\n\nimport { useAlbumMetadata } from '../hooks/useAlbums'\nimport './FilterBar.css'\n\nfunction FilterBar({ albums, filters, onChange, sortBy, onSortChange }) {\n  const { years, artists, pickers } = useAlbumMetadata(albums)\n  \n  const updateFilter = (key, value) => {\n    onChange({ ...filters, [key]: value })\n  }\n  \n  const clearFilters = () => {\n    onChange({})\n  }\n  \n  const hasActiveFilters = Object.values(filters).some(v => v)\n  \n  return (\n    <div className=\"filter-bar\">\n      <div className=\"filter-group\">\n        <label htmlFor=\"year-filter\">Year</label>\n        <select \n          id=\"year-filter\"\n          value={filters.year || ''} \n          onChange={(e) => updateFilter('year', e.target.value)}\n        >\n          <option value=\"\">All Years</option>\n          {years.map(year => (\n            <option key={year} value={year}>{year}</option>\n          ))}\n        </select>\n      </div>\n      \n      <div className=\"filter-group\">\n        <label htmlFor=\"artist-filter\">Artist</label>\n        <select \n          id=\"artist-filter\"\n          value={filters.artist || ''} \n          onChange={(e) => updateFilter('artist', e.target.value)}\n        >\n          <option value=\"\">All Artists</option>\n          {artists.map(artist => (\n            <option key={artist} value={artist}>{artist}</option>\n          ))}\n        </select>\n      </div>\n      \n      <div className=\"filter-group\">\n        <label htmlFor=\"picker-filter\">Picker</label>\n        <select \n          id=\"picker-filter\"\n          value={filters.picker || ''} \n          onChange={(e) => updateFilter('picker', e.target.value)}\n        >\n          <option value=\"\">All Pickers</option>\n          {pickers.map(picker => (\n            <option key={picker} value={picker}>{picker}</option>\n          ))}\n        </select>\n      </div>\n      \n      <div className=\"filter-group\">\n        <label htmlFor=\"sort-select\">Sort By</label>\n        <select \n          id=\"sort-select\"\n          value={sortBy || 'date'} \n          onChange={(e) => onSortChange(e.target.value)}\n        >\n          <option value=\"date\">Date Added</option>\n          <option value=\"artist\">Artist</option>\n          <option value=\"album\">Album</option>\n          <option value=\"year\">Release Year</option>\n          <option value=\"picker\">Picker</option>\n        </select>\n      </div>\n      \n      {hasActiveFilters && (\n        <button className=\"clear-filters\" onClick={clearFilters}>\n          Clear Filters\n        </button>\n      )}\n    </div>\n  )\n}\n\nexport default FilterBar\n\nCreate src/components/FilterBar.css:\n\n.filter-bar {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 1rem;\n  padding: 1rem;\n  background: var(--filter-bg);\n  border-radius: 8px;\n  margin: 1rem 0;\n  align-items: flex-end;\n}\n\n.filter-group {\n  display: flex;\n  flex-direction: column;\n  gap: 0.25rem;\n  min-width: 150px;\n}\n\n.filter-group label {\n  font-size: 0.85rem;\n  color: var(--text-secondary);\n  font-weight: 500;\n}\n\n.filter-group select {\n  padding: 0.5rem;\n  font-size: 0.95rem;\n  border: 1px solid var(--border-color);\n  border-radius: 4px;\n  background: var(--input-bg);\n  color: var(--text-primary);\n  cursor: pointer;\n}\n\n.filter-group select:focus {\n  outline: none;\n  border-color: var(--accent-color);\n}\n\n.clear-filters {\n  padding: 0.5rem 1rem;\n  background: var(--button-bg);\n  border: none;\n  border-radius: 4px;\n  cursor: pointer;\n  color: var(--text-primary);\n  font-size: 0.95rem;\n}\n\n.clear-filters:hover {\n  background: var(--button-hover);\n}\n\n@media (max-width: 768px) {\n  .filter-bar {\n    flex-direction: column;\n  }\n  \n  .filter-group {\n    width: 100%;\n  }\n}",
        "testStrategy": "Component tests:\n- Test filter dropdowns populate from album metadata\n- Test filter selection updates parent state\n- Test clear filters button\n- Test sort dropdown changes\n- Test responsive layout\n- Test with empty albums array",
        "priority": "medium",
        "dependencies": [
          "14",
          "15"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "21",
        "title": "Implement Dark Mode Styling",
        "description": "Create comprehensive dark mode CSS with CSS variables for theming",
        "details": "Create src/styles/index.css:\n\n:root {\n  /* Dark theme (default) */\n  --bg-primary: #0f0f0f;\n  --bg-secondary: #1a1a1a;\n  --card-bg: #1e1e1e;\n  --filter-bg: #1a1a1a;\n  --input-bg: #252525;\n  --button-bg: #2a2a2a;\n  --button-hover: #353535;\n  \n  --text-primary: #e5e5e5;\n  --text-secondary: #a0a0a0;\n  --text-tertiary: #707070;\n  \n  --border-color: #333;\n  --accent-color: #1db954; /* Spotify green */\n  --artwork-bg: #252525;\n  \n  --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.3);\n  --shadow-md: 0 4px 8px rgba(0, 0, 0, 0.4);\n  --shadow-lg: 0 8px 16px rgba(0, 0, 0, 0.5);\n}\n\n/* Optional light mode (commented out for now)\n[data-theme=\"light\"] {\n  --bg-primary: #ffffff;\n  --bg-secondary: #f5f5f5;\n  --card-bg: #ffffff;\n  --filter-bg: #f8f8f8;\n  --input-bg: #ffffff;\n  --button-bg: #e5e5e5;\n  --button-hover: #d0d0d0;\n  \n  --text-primary: #1a1a1a;\n  --text-secondary: #606060;\n  --text-tertiary: #909090;\n  \n  --border-color: #e0e0e0;\n  --accent-color: #1db954;\n  --artwork-bg: #f0f0f0;\n  \n  --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.08);\n  --shadow-md: 0 4px 8px rgba(0, 0, 0, 0.12);\n  --shadow-lg: 0 8px 16px rgba(0, 0, 0, 0.16);\n}\n*/\n\n* {\n  box-sizing: border-box;\n  margin: 0;\n  padding: 0;\n}\n\nbody {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', \n    'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', \n    'Helvetica Neue', sans-serif;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  background: var(--bg-primary);\n  color: var(--text-primary);\n  line-height: 1.5;\n}\n\n#root {\n  min-height: 100vh;\n}\n\n.app {\n  min-height: 100vh;\n  display: flex;\n  flex-direction: column;\n}\n\nheader {\n  background: var(--bg-secondary);\n  padding: 2rem 1rem;\n  text-align: center;\n  border-bottom: 1px solid var(--border-color);\n}\n\nheader h1 {\n  font-size: 2.5rem;\n  margin-bottom: 1rem;\n  font-weight: 700;\n}\n\nmain {\n  flex: 1;\n}\n\n.loading {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  min-height: 100vh;\n  font-size: 1.5rem;\n  color: var(--text-secondary);\n}\n\n/* Scrollbar styling */\n::-webkit-scrollbar {\n  width: 12px;\n}\n\n::-webkit-scrollbar-track {\n  background: var(--bg-secondary);\n}\n\n::-webkit-scrollbar-thumb {\n  background: var(--button-bg);\n  border-radius: 6px;\n}\n\n::-webkit-scrollbar-thumb:hover {\n  background: var(--button-hover);\n}\n\n/* Focus states for accessibility */\nbutton:focus-visible,\ninput:focus-visible,\nselect:focus-visible {\n  outline: 2px solid var(--accent-color);\n  outline-offset: 2px;\n}",
        "testStrategy": "Manual testing:\n- Verify all components use CSS variables\n- Test dark mode appearance across all components\n- Verify contrast ratios meet WCAG AA standards\n- Test on different screen sizes\n- Test scrollbar styling in different browsers\n- Verify focus states visible for accessibility",
        "priority": "medium",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "22",
        "title": "Create Netlify Deployment Configuration",
        "description": "Set up Netlify configuration for auto-deployment from GitHub, including build settings and redirects",
        "details": "Create website/netlify.toml:\n\n[build]\n  command = \"npm run build\"\n  publish = \"dist\"\n  \n[build.environment]\n  NODE_VERSION = \"18\"\n\n# Redirect rules\n[[redirects]]\n  from = \"/*\"\n  to = \"/index.html\"\n  status = 200\n\n# Headers for security and caching\n[[headers]]\n  for = \"/*\"\n  [headers.values]\n    X-Frame-Options = \"DENY\"\n    X-Content-Type-Options = \"nosniff\"\n    Referrer-Policy = \"strict-origin-when-cross-origin\"\n\n[[headers]]\n  for = \"/*.js\"\n  [headers.values]\n    Cache-Control = \"public, max-age=31536000, immutable\"\n\n[[headers]]\n  for = \"/*.css\"\n  [headers.values]\n    Cache-Control = \"public, max-age=31536000, immutable\"\n\n[[headers]]\n  for = \"/data.json\"\n  [headers.values]\n    Cache-Control = \"public, max-age=300, must-revalidate\"\n\nUpdate website/.gitignore:\nnode_modules/\ndist/\n.env\n*.log\n.netlify/\n\nCreate DEPLOYMENT_WEBSITE.md:\n\n# Website Deployment Guide\n\n## Netlify Setup\n\n1. Create Netlify account\n2. Connect to GitHub repository (website repo)\n3. Configure build settings:\n   - Base directory: `website/`\n   - Build command: `npm run build`\n   - Publish directory: `website/dist`\n4. Deploy site\n5. Configure custom domain (optional)\n\n## GitHub Repository Structure\n\nThe website repo should contain:\n```\n/\nâ”œâ”€â”€ data.json          â† Updated by bot pipeline\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ App.jsx\nâ”‚   â”œâ”€â”€ components/\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ public/\nâ”œâ”€â”€ index.html\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ vite.config.js\nâ””â”€â”€ netlify.toml\n```\n\ndata.json lives at repo root and is copied to dist/ during build.\n\n## Deploy Trigger\n\nNetlify watches the GitHub repo for changes. When the bot pushes an updated data.json:\n1. GitHub receives commit\n2. Netlify detects commit\n3. Netlify runs build (npm run build)\n4. Netlify deploys to CDN\n5. Site updates within 1-2 minutes\n\n## Manual Deploy\n\nFor testing or emergency updates:\n```bash\ncd website/\nnpm run build\nnetlify deploy --prod\n```\n\n## Monitoring\n\n- Netlify dashboard shows build logs and deploy status\n- Set up deploy notifications (email, Slack, etc.)\n- Monitor site uptime via Netlify analytics",
        "testStrategy": "Deployment validation:\n- Test Netlify build succeeds\n- Verify dist/ contains all assets + data.json\n- Test site loads correctly\n- Test SPA routing works (404s redirect to index.html)\n- Verify cache headers set correctly\n- Test security headers present\n- Test custom domain (if configured)\n- Trigger test commit and verify auto-deploy",
        "priority": "high",
        "dependencies": [
          "14"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "23",
        "title": "Create GitHub Website Repository and Integration",
        "description": "Set up the GitHub repository for the website with proper structure and ensure data.json is at repo root for Netlify",
        "details": "Manual setup steps:\n\n1. Create new GitHub repo: `aotw-website` (or chosen name)\n2. Initialize with README.md\n3. Clone locally\n4. Set up directory structure:\n```\n/\nâ”œâ”€â”€ data.json          â† Pipeline updates this\nâ”œâ”€â”€ src/\nâ”‚   â””â”€â”€ (React code)\nâ”œâ”€â”€ public/\nâ”œâ”€â”€ index.html\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ vite.config.js\nâ””â”€â”€ netlify.toml\n```\n\n5. Update vite.config.js to copy data.json to dist/:\n```js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\nimport { copyFileSync } from 'fs'\n\nexport default defineConfig({\n  plugins: [\n    react(),\n    {\n      name: 'copy-data-json',\n      closeBundle() {\n        // Copy data.json from repo root to dist/\n        try {\n          copyFileSync('data.json', 'dist/data.json')\n          console.log('Copied data.json to dist/')\n        } catch (err) {\n          console.warn('data.json not found, skipping copy')\n        }\n      }\n    }\n  ],\n  build: {\n    outDir: 'dist',\n    assetsDir: 'assets'\n  }\n})\n```\n\n6. Create initial data.json at repo root:\n```json\n[\n  {\n    \"spotify_album_id\": \"example123456789012345\",\n    \"pick_number\": 1,\n    \"picked_at\": \"2024-01-01\",\n    \"artist\": \"Example Artist\",\n    \"album\": \"Example Album\",\n    \"year\": \"2024\",\n    \"artwork_url\": \"https://example.com/artwork.jpg\",\n    \"spotify_url\": \"https://open.spotify.com/album/example\",\n    \"picker\": \"Test User\"\n  }\n]\n```\n\n7. Commit and push initial structure\n\n8. Create GitHub fine-grained personal access token:\n   - Go to GitHub Settings > Developer settings > Personal access tokens > Fine-grained tokens\n   - Create new token\n   - Set expiration (1 year recommended)\n   - Repository access: Only select repositories > select website repo\n   - Permissions: Contents (Read and Write)\n   - Generate token and save securely\n\n9. Add token to Railway env vars as GITHUB_TOKEN\n\n10. Test GitHub API access from Railway:\n```python\nimport os\nimport requests\n\ntoken = os.getenv('GITHUB_TOKEN')\nheaders = {'Authorization': f'token {token}'}\nresponse = requests.get(\n    'https://api.github.com/repos/OWNER/REPO/contents/data.json',\n    headers=headers\n)\nprint(response.status_code)  # Should be 200\n```",
        "testStrategy": "Integration validation:\n- Verify repo created and accessible\n- Verify data.json at repo root\n- Test local build copies data.json to dist/\n- Verify GitHub token has correct permissions\n- Test API read access to data.json\n- Test API write access (update data.json)\n- Verify commit appears in GitHub history",
        "priority": "high",
        "dependencies": [
          "14",
          "22"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "24",
        "title": "Write Comprehensive Integration Tests",
        "description": "Create end-to-end integration tests covering the full pipeline from Telegram message to website update",
        "details": "Create tests/test_integration.py:\n\nimport pytest\nimport json\nfrom unittest.mock import Mock, patch, MagicMock\nimport sys\nimport os\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))\n\nfrom pipeline import process_album\nfrom export_json import export_sheet_to_json\nfrom github_push import push_data_to_github\n\nclass TestFullPipeline:\n    \"\"\"Test the complete pipeline flow.\"\"\"\n    \n    @pytest.fixture\n    def mock_spotify_response(self):\n        return {\n            'id': '0SeRWS3scHWplJhMppd6rJ',\n            'name': 'Under the Table and Dreaming',\n            'artists': [{'name': 'Dave Matthews Band'}],\n            'release_date': '1994-09-27',\n            'release_date_precision': 'day',\n            'images': [\n                {'url': 'large.jpg'},\n                {'url': 'medium.jpg'},\n                {'url': 'small.jpg'}\n            ]\n        }\n    \n    @pytest.fixture\n    def mock_worksheet(self):\n        worksheet = MagicMock()\n        # Mock header row\n        worksheet.find.side_effect = [\n            Mock(row=1, col=1),  # Pick cell\n            Mock(row=1, col=2)   # Date cell\n        ]\n        worksheet.row_values.return_value = [\n            'Pick', 'Date', 'Artist', 'Album', 'Year', \n            'spotify_album_url', 'artwork_url', 'Picker'\n        ]\n        worksheet.col_values.return_value = ['Pick', '1', '2', '3']\n        worksheet.append_row.return_value = None\n        worksheet.get_all_values.return_value = [\n            ['Pick', 'Date', 'Artist', 'Album', 'Year', 'spotify_album_url', 'artwork_url', 'Picker'],\n            ['1', '1/1/2024', 'Artist 1', 'Album 1', '2024', 'https://open.spotify.com/album/abc123', 'art1.jpg', 'User1']\n        ]\n        return worksheet\n    \n    @pytest.mark.asyncio\n    async def test_full_pipeline_success(self, mock_spotify_response, mock_worksheet):\n        \"\"\"Test complete successful flow.\"\"\"\n        url = 'https://open.spotify.com/album/0SeRWS3scHWplJhMppd6rJ'\n        \n        with patch('pipeline.get_spotify_api') as mock_sp, \\\n             patch('pipeline.get_album_info') as mock_album_info, \\\n             patch('pipeline.get_google_sheet') as mock_sheet, \\\n             patch('pipeline.export_and_push') as mock_export:\n            \n            mock_sp.return_value = Mock()\n            mock_album_info.return_value = {\n                'spotify_album_id': '0SeRWS3scHWplJhMppd6rJ',\n                'Artist': 'Dave Matthews Band',\n                'Album': 'Under the Table and Dreaming',\n                'Year': 1994,\n                'spotify_album_url': url,\n                'artwork_url': 'medium.jpg'\n            }\n            mock_sheet.return_value = mock_worksheet\n            mock_export.return_value = (True, 'Website will update shortly')\n            \n            result = await process_album(url)\n            \n            assert result['success'] is True\n            assert 'Dave Matthews Band' in result['message']\n            mock_worksheet.append_row.assert_called_once()\n            mock_export.assert_called_once()\n    \n    @pytest.mark.asyncio\n    async def test_duplicate_detection(self, mock_worksheet):\n        \"\"\"Test duplicate album is rejected.\"\"\"\n        url = 'https://open.spotify.com/album/abc123'  # Already in mock sheet\n        \n        with patch('pipeline.get_google_sheet') as mock_sheet:\n            mock_sheet.return_value = mock_worksheet\n            \n            result = await process_album(url)\n            \n            assert result['success'] is False\n            assert 'Already added' in result['message']\n    \n    def test_json_export(self, mock_worksheet):\n        \"\"\"Test JSON export from sheet.\"\"\"\n        with patch('export_json.get_google_sheet') as mock_sheet:\n            mock_sheet.return_value = mock_worksheet\n            \n            albums = export_sheet_to_json(output_path='/tmp/test_data.json')\n            \n            assert len(albums) == 1\n            assert albums[0]['spotify_album_id'] == 'abc123'\n            assert albums[0]['artist'] == 'Artist 1'\n            \n            # Verify file written\n            with open('/tmp/test_data.json') as f:\n                data = json.load(f)\n                assert len(data) == 1\n    \n    def test_github_push(self):\n        \"\"\"Test GitHub API push.\"\"\"\n        json_content = json.dumps([{'test': 'data'}])\n        \n        with patch('github_push.requests.get') as mock_get, \\\n             patch('github_push.requests.put') as mock_put, \\\n             patch.dict(os.environ, {\n                 'GITHUB_TOKEN': 'test_token',\n                 'GITHUB_REPO_OWNER': 'test_owner',\n                 'GITHUB_REPO_NAME': 'test_repo'\n             }):\n            \n            mock_get.return_value = Mock(status_code=200, json=lambda: {'sha': 'abc123'})\n            mock_put.return_value = Mock(\n                status_code=200,\n                json=lambda: {'commit': {'sha': 'def456'}}\n            )\n            \n            result = push_data_to_github(json_content, 'Test commit')\n            \n            assert result is True\n            mock_put.assert_called_once()\n\nCreate tests/test_validation.py:\n\nimport pytest\nimport sys\nimport os\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))\n\nfrom validation import (\n    is_valid_spotify_album_url,\n    extract_spotify_album_id,\n    validate_album_metadata\n)\n\nclass TestValidation:\n    def test_valid_album_urls(self):\n        valid_urls = [\n            'https://open.spotify.com/album/0SeRWS3scHWplJhMppd6rJ',\n            'https://open.spotify.com/album/0SeRWS3scHWplJhMppd6rJ?si=abc123'\n        ]\n        for url in valid_urls:\n            assert is_valid_spotify_album_url(url) is True\n    \n    def test_invalid_urls(self):\n        invalid_urls = [\n            'https://open.spotify.com/track/5SBMNVrRM8xZpyGYTYtfR9',\n            'https://open.spotify.com/playlist/37i9dQZF1DXcBWIGoYBM5M',\n            'https://open.spotify.com/artist/4Z8W4fKeB5YxbusRsdQVPb',\n            'bad_url',\n            ''\n        ]\n        for url in invalid_urls:\n            assert is_valid_spotify_album_url(url) is False\n    \n    def test_extract_album_id(self):\n        url = 'https://open.spotify.com/album/0SeRWS3scHWplJhMppd6rJ?si=test'\n        album_id = extract_spotify_album_id(url)\n        assert album_id == '0SeRWS3scHWplJhMppd6rJ'\n    \n    def test_metadata_validation(self):\n        valid_metadata = {\n            'Artist': 'Test Artist',\n            'Album': 'Test Album',\n            'Year': '2024',\n            'spotify_album_url': 'https://open.spotify.com/album/test',\n            'artwork_url': 'https://example.com/art.jpg'\n        }\n        is_valid, error = validate_album_metadata(valid_metadata)\n        assert is_valid is True\n        \n        invalid_metadata = {'Artist': 'Test'}\n        is_valid, error = validate_album_metadata(invalid_metadata)\n        assert is_valid is False\n        assert 'Missing required fields' in error\n\nRun tests:\npytest tests/ -v --cov=src --cov-report=html",
        "testStrategy": "Test execution:\n- Run all unit tests: pytest tests/\n- Run integration tests: pytest tests/test_integration.py\n- Check coverage: Should be >80% for critical paths\n- Test in CI/CD pipeline (GitHub Actions)\n- Manual end-to-end test with real credentials in staging",
        "priority": "medium",
        "dependencies": [
          "7",
          "9",
          "10",
          "11"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "25",
        "title": "Update Environment Configuration and Documentation",
        "description": "Update environment.yml with all dependencies and create comprehensive setup documentation",
        "details": "Update environment.yml:\n\nname: spotify-env\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.10\n  - pip\n  - pip:\n      - spotipy>=2.23.0\n      - gspread>=5.10.0\n      - python-telegram-bot>=20.0\n      - requests>=2.31.0\n      - pytest>=7.4.0\n      - pytest-asyncio>=0.21.0\n      - pytest-cov>=4.1.0\n      - python-dotenv>=1.0.0\n\nCreate requirements.txt for Railway:\n\nspotipy>=2.23.0\ngspread>=5.10.0\npython-telegram-bot>=20.0\nrequests>=2.31.0\n\nCreate .env.example:\n\n# Telegram\nTELEGRAM_BOT_TOKEN=your_bot_token_here\nTELEGRAM_ALLOWED_CHAT_ID=your_chat_id_here\n\n# Spotify\nSPOTIFY_CLIENT_ID=your_client_id_here\nSPOTIFY_CLIENT_SECRET=your_client_secret_here\n\n# Google Sheets\nGOOGLE_SHEET_ID=1h1uDCZPqJovFfUKPzfPgUwUOHjFdCXHWVhUE6VvFA_s\nGOOGLE_SHEET_TAB=Sheet1\nGOOGLE_SERVICE_ACCOUNT_JSON={\"type\":\"service_account\",...}\n\n# GitHub\nGITHUB_TOKEN=your_github_token_here\nGITHUB_REPO_OWNER=your_username\nGITHUB_REPO_NAME=aotw-website\n\nUpdate CLAUDE.md with new architecture:\n\n## Project Overview\n\nAn automated \"Album of the Week\" pipeline with Telegram bot trigger, Google Sheets backup, and React website.\n\n## Architecture\n\n1. **Telegram Bot** (python-telegram-bot, Railway)\n   - Monitors group chat for `@aotw <spotify_url>`\n   - Validates URL, checks for duplicates\n   - Triggers pipeline\n\n2. **Pipeline** (src/pipeline.py)\n   - Fetches album metadata from Spotify\n   - Appends to Google Sheet\n   - Exports sheet to data.json\n   - Pushes to GitHub via API\n\n3. **Website** (React + Vite, Netlify)\n   - Loads data.json at page load\n   - Interactive album grid with search/filter\n   - Auto-deploys on GitHub commit\n\n## Setup\n\n### Local Development\n```bash\nmamba env create -f environment.yml\nmamba activate spotify-env\ncp .env.example .env\n# Fill in .env with your credentials\npython src/telegram_bot.py\n```\n\n### Website Development\n```bash\ncd website/\nnpm install\nnpm run dev\n```\n\n## Testing\n```bash\npytest tests/ -v\n```\n\n## Deployment\n\nSee DEPLOYMENT.md for Railway and Netlify setup.\n\nCreate README.md:\n\n# Album of the Week - Automated Pipeline\n\nAutomated system for tracking weekly album picks via Telegram bot, with public website.\n\n## Features\n\n- ðŸ¤– Telegram bot trigger (`@aotw <spotify_url>`)\n- âœ… URL validation and duplicate detection\n- ðŸ“Š Google Sheets backup (300+ albums)\n- ðŸŒ React website with search/filter\n- ðŸš€ Auto-deploy to Netlify on new pick\n- ðŸŽµ Direct Spotify integration\n\n## Tech Stack\n\n- **Bot**: python-telegram-bot (Railway)\n- **Backend**: Python 3.10, spotipy, gspread\n- **Website**: React + Vite (Netlify)\n- **Data**: Google Sheets â†’ JSON â†’ GitHub â†’ Netlify\n\n## Quick Start\n\nSee [CLAUDE.md](CLAUDE.md) for setup instructions.\n\n## Documentation\n\n- [DEPLOYMENT.md](DEPLOYMENT.md) - Railway bot deployment\n- [DEPLOYMENT_WEBSITE.md](DEPLOYMENT_WEBSITE.md) - Netlify website deployment\n- [CLAUDE.md](CLAUDE.md) - Development guide",
        "testStrategy": "Documentation validation:\n- Test local setup from scratch following CLAUDE.md\n- Verify all dependencies install correctly\n- Test .env.example has all required vars\n- Test README is clear and accurate\n- Have another developer follow setup docs",
        "priority": "medium",
        "dependencies": [
          "6",
          "13",
          "22"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "26",
        "title": "Perform End-to-End System Test and Validation",
        "description": "Execute complete end-to-end test of the entire system from Telegram message to live website update",
        "details": "End-to-end test checklist:\n\n## Pre-test Setup\n1. âœ… Railway bot deployed and running\n2. âœ… Netlify website deployed\n3. âœ… GitHub repo connected\n4. âœ… All env vars set correctly\n5. âœ… Telegram bot added to test group\n6. âœ… Test Spotify album URL prepared\n\n## Test Flow\n1. Send message in Telegram: `@aotw https://open.spotify.com/album/TEST_ALBUM`\n2. Verify bot replies with confirmation message\n3. Check Railway logs:\n   - Message received logged\n   - URL validation passed\n   - Dedup check passed\n   - Spotify lookup succeeded\n   - Sheet append succeeded\n   - JSON export succeeded\n   - GitHub push succeeded\n4. Check Google Sheet:\n   - New row added with correct data\n   - Pick number auto-filled by formula\n   - Date is correct (last date + 7 days)\n5. Check GitHub repo:\n   - New commit appears\n   - Commit message is correct\n   - data.json updated with new album\n6. Check Netlify:\n   - Deploy triggered automatically\n   - Build succeeds\n   - Deploy completes\n7. Check website:\n   - Visit live URL\n   - New album appears in grid\n   - Search for album artist (should find it)\n   - Click album card (opens Spotify)\n   - Check album metadata correct\n\n## Error Scenario Tests\n1. Send invalid URL â†’ verify error message\n2. Send duplicate album â†’ verify duplicate message\n3. Send track URL (not album) â†’ verify error\n4. Simulate Spotify API failure â†’ verify graceful error\n5. Simulate GitHub push failure â†’ verify partial success message\n\n## Performance Tests\n1. Time full pipeline (should be <10 seconds)\n2. Website loads in <2 seconds\n3. Search is responsive (no lag)\n4. 300+ albums render smoothly\n\n## Monitoring Setup\n1. Configure Railway log retention\n2. Set up Netlify deploy notifications\n3. Test bot error handling (catch exceptions, log, reply to user)\n4. Document common issues and solutions\n\n## Rollback Plan\n1. If bot fails: Check Railway logs, restart service\n2. If website fails: Rollback to previous Netlify deploy\n3. If data corrupted: Regenerate JSON from Google Sheet\n4. Emergency contacts and access",
        "testStrategy": "Validation criteria:\n- All test flows complete successfully\n- Error scenarios handled gracefully\n- Performance meets targets (<10s pipeline, <2s page load)\n- Logs show correct execution flow\n- No secrets leaked in logs\n- User receives clear feedback at each stage\n- Document any issues found and fixes applied",
        "priority": "high",
        "dependencies": [
          "13",
          "22",
          "23",
          "24"
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-25T04:15:02.915Z",
      "taskCount": 26,
      "completedCount": 6,
      "tags": [
        "master"
      ]
    }
  }
}